import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from models.yolo import YOLOv5s
from models.loss import ComputeLoss
from augmentation import YOLOv5Augmentation
from params_yolo import get_default_config
import seaborn as sns

def load_model(model_path, device='cpu'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    model = YOLOv5s().to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    return model

def preprocess_image(img_path, img_size=640):
    """é¢„å¤„ç†å•å¼ å›¾ç‰‡"""
    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
    if img is None:
        raise FileNotFoundError(f"æ— æ³•è¯»å–å›¾ç‰‡: {img_path}")
    
    # å•é€šé“å¤„ç†
    if len(img.shape) == 2 or (len(img.shape) == 3 and img.shape[2] == 1):
        img = cv2.merge([img, img, img])
    
    # letterboxå¤„ç†
    augmentor = YOLOv5Augmentation()
    img, ratio, (dw, dh) = augmentor.letterbox(img, new_shape=(img_size, img_size), auto=False)
    
    # è½¬æ¢ä¸ºtensor
    img_tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0
    img_tensor = img_tensor.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    
    return img_tensor, img, ratio, (dw, dh)

def analyze_confidence_distribution(pred_outputs, save_path="debug_output/confidence_distribution.png"):
    """åˆ†æç½®ä¿¡åº¦åˆ†å¸ƒ"""
    os.makedirs("debug_output", exist_ok=True)
    
    all_confs = []
    for pred in pred_outputs:
        # pred shape: [batch, anchors, height, width, channels]
        conf = torch.sigmoid(pred[..., 4])  # åº”ç”¨sigmoidåˆ°ç½®ä¿¡åº¦
        all_confs.extend(conf.flatten().cpu().numpy())
    
    plt.figure(figsize=(12, 4))
    
    # ç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
    plt.subplot(1, 3, 1)
    plt.hist(all_confs, bins=50, alpha=0.7, color='blue')
    plt.xlabel('Confidence Score')
    plt.ylabel('Count')
    plt.title('Confidence Distribution')
    plt.axvline(0.01, color='red', linestyle='--', label='thresh=0.01')
    plt.axvline(0.05, color='orange', linestyle='--', label='thresh=0.05')
    plt.legend()
    
    # ç½®ä¿¡åº¦ç´¯ç§¯åˆ†å¸ƒ
    plt.subplot(1, 3, 2)
    sorted_confs = np.sort(all_confs)
    cumulative = np.arange(1, len(sorted_confs) + 1) / len(sorted_confs)
    plt.plot(sorted_confs, cumulative)
    plt.xlabel('Confidence Score')
    plt.ylabel('Cumulative Probability')
    plt.title('Confidence CDF')
    plt.axvline(0.01, color='red', linestyle='--', label='thresh=0.01')
    plt.axvline(0.05, color='orange', linestyle='--', label='thresh=0.05')
    plt.legend()
    
    # ç½®ä¿¡åº¦ç»Ÿè®¡
    plt.subplot(1, 3, 3)
    stats = {
        'Mean': np.mean(all_confs),
        'Std': np.std(all_confs),
        'Max': np.max(all_confs),
        'Min': np.min(all_confs),
        '>0.01': np.sum(np.array(all_confs) > 0.01) / len(all_confs),
        '>0.05': np.sum(np.array(all_confs) > 0.05) / len(all_confs),
        '>0.1': np.sum(np.array(all_confs) > 0.1) / len(all_confs)
    }
    
    y_pos = np.arange(len(stats))
    plt.barh(y_pos, list(stats.values()))
    plt.yticks(y_pos, list(stats.keys()))
    plt.xlabel('Value')
    plt.title('Confidence Statistics')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"ç½®ä¿¡åº¦åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path}")
    print(f"ç½®ä¿¡åº¦ç»Ÿè®¡: mean={stats['Mean']:.4f}, std={stats['Std']:.4f}, >0.01: {stats['>0.01']:.2%}")
    
    return stats

def analyze_box_coordinates(pred_outputs, save_path="debug_output/box_coordinate_distribution.png"):
    """åˆ†æé¢„æµ‹æ¡†åæ ‡åˆ†å¸ƒ"""
    os.makedirs("debug_output", exist_ok=True)
    
    all_boxes = []
    all_wh = []
    
    for pred in pred_outputs:
        # pred shape: [batch, anchors, height, width, channels]
        boxes = pred[..., :4]  # x, y, w, h
        conf = torch.sigmoid(pred[..., 4])
        
        # åªåˆ†æç½®ä¿¡åº¦>0.01çš„æ¡†
        mask = conf > 0.01
        valid_boxes = boxes[mask]
        
        if len(valid_boxes) > 0:
            all_boxes.extend(valid_boxes.cpu().numpy())
            all_wh.extend(valid_boxes[:, 2:4].cpu().numpy())  # w, h
    
    if len(all_boxes) == 0:
        print("âš ï¸ æ²¡æœ‰ç½®ä¿¡åº¦>0.01çš„é¢„æµ‹æ¡†ï¼è¿™æ˜¯é—®é¢˜çš„æ ¸å¿ƒï¼")
        return
    
    all_boxes = np.array(all_boxes)
    all_wh = np.array(all_wh)
    
    plt.figure(figsize=(15, 10))
    
    # x, y åæ ‡åˆ†å¸ƒ
    plt.subplot(2, 3, 1)
    plt.scatter(all_boxes[:, 0], all_boxes[:, 1], alpha=0.5, s=1)
    plt.xlabel('X coordinate')
    plt.ylabel('Y coordinate')
    plt.title('XY Coordinate Distribution')
    
    # w, h å°ºå¯¸åˆ†å¸ƒ
    plt.subplot(2, 3, 2)
    plt.scatter(all_wh[:, 0], all_wh[:, 1], alpha=0.5, s=1)
    plt.xlabel('Width')
    plt.ylabel('Height')
    plt.title('Width-Height Distribution')
    
    # x åæ ‡ç›´æ–¹å›¾
    plt.subplot(2, 3, 3)
    plt.hist(all_boxes[:, 0], bins=50, alpha=0.7, color='red')
    plt.xlabel('X coordinate')
    plt.ylabel('Count')
    plt.title('X Distribution')
    
    # y åæ ‡ç›´æ–¹å›¾
    plt.subplot(2, 3, 4)
    plt.hist(all_boxes[:, 1], bins=50, alpha=0.7, color='green')
    plt.xlabel('Y coordinate')
    plt.ylabel('Count')
    plt.title('Y Distribution')
    
    # w å°ºå¯¸ç›´æ–¹å›¾
    plt.subplot(2, 3, 5)
    plt.hist(all_wh[:, 0], bins=50, alpha=0.7, color='blue')
    plt.xlabel('Width')
    plt.ylabel('Count')
    plt.title('Width Distribution')
    
    # h å°ºå¯¸ç›´æ–¹å›¾
    plt.subplot(2, 3, 6)
    plt.hist(all_wh[:, 1], bins=50, alpha=0.7, color='purple')
    plt.xlabel('Height')
    plt.ylabel('Count')
    plt.title('Height Distribution')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"åæ ‡åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path}")
    print(f"æœ‰æ•ˆé¢„æµ‹æ¡†æ•°é‡: {len(all_boxes)}")
    print(f"åæ ‡èŒƒå›´: x=[{all_boxes[:, 0].min():.2f}, {all_boxes[:, 0].max():.2f}], y=[{all_boxes[:, 1].min():.2f}, {all_boxes[:, 1].max():.2f}]")
    print(f"å°ºå¯¸èŒƒå›´: w=[{all_wh[:, 0].min():.2f}, {all_wh[:, 0].max():.2f}], h=[{all_wh[:, 1].min():.2f}, {all_wh[:, 1].max():.2f}]")

def analyze_ground_truth_distribution(data_dir, save_path="debug_output/ground_truth_distribution.png"):
    """åˆ†æçœŸå®æ ‡ç­¾åˆ†å¸ƒ"""
    os.makedirs("debug_output", exist_ok=True)
    
    label_dir = os.path.join(data_dir, "labels")
    if not os.path.exists(label_dir):
        print(f"æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {label_dir}")
        return
    
    all_boxes = []
    all_wh = []
    
    for label_file in os.listdir(label_dir):
        if not label_file.endswith('.txt'):
            continue
        
        label_path = os.path.join(label_dir, label_file)
        try:
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        cls, x, y, w, h = map(float, parts[:5])
                        all_boxes.append([x, y, w, h])
                        all_wh.append([w, h])
        except Exception as e:
            print(f"è¯»å–æ ‡ç­¾æ–‡ä»¶å¤±è´¥ {label_file}: {e}")
    
    if len(all_boxes) == 0:
        print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ ‡ç­¾æ•°æ®ï¼")
        return
    
    all_boxes = np.array(all_boxes)
    all_wh = np.array(all_wh)
    
    plt.figure(figsize=(15, 10))
    
    # x, y åæ ‡åˆ†å¸ƒ
    plt.subplot(2, 3, 1)
    plt.scatter(all_boxes[:, 0], all_boxes[:, 1], alpha=0.5, s=10, color='red')
    plt.xlabel('X coordinate (normalized)')
    plt.ylabel('Y coordinate (normalized)')
    plt.title('GT XY Coordinate Distribution')
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    
    # w, h å°ºå¯¸åˆ†å¸ƒ
    plt.subplot(2, 3, 2)
    plt.scatter(all_wh[:, 0], all_wh[:, 1], alpha=0.5, s=10, color='blue')
    plt.xlabel('Width (normalized)')
    plt.ylabel('Height (normalized)')
    plt.title('GT Width-Height Distribution')
    
    # x åæ ‡ç›´æ–¹å›¾
    plt.subplot(2, 3, 3)
    plt.hist(all_boxes[:, 0], bins=20, alpha=0.7, color='red')
    plt.xlabel('X coordinate')
    plt.ylabel('Count')
    plt.title('GT X Distribution')
    
    # y åæ ‡ç›´æ–¹å›¾
    plt.subplot(2, 3, 4)
    plt.hist(all_boxes[:, 1], bins=20, alpha=0.7, color='green')
    plt.xlabel('Y coordinate')
    plt.ylabel('Count')
    plt.title('GT Y Distribution')
    
    # w å°ºå¯¸ç›´æ–¹å›¾
    plt.subplot(2, 3, 5)
    plt.hist(all_wh[:, 0], bins=20, alpha=0.7, color='blue')
    plt.xlabel('Width')
    plt.ylabel('Count')
    plt.title('GT Width Distribution')
    
    # h å°ºå¯¸ç›´æ–¹å›¾
    plt.subplot(2, 3, 6)
    plt.hist(all_wh[:, 1], bins=20, alpha=0.7, color='purple')
    plt.xlabel('Height')
    plt.ylabel('Count')
    plt.title('GT Height Distribution')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"çœŸå®æ ‡ç­¾åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path}")
    print(f"æ€»æ ‡ç­¾æ•°é‡: {len(all_boxes)}")
    print(f"æ ‡ç­¾åæ ‡èŒƒå›´: x=[{all_boxes[:, 0].min():.3f}, {all_boxes[:, 0].max():.3f}], y=[{all_boxes[:, 1].min():.3f}, {all_boxes[:, 1].max():.3f}]")
    print(f"æ ‡ç­¾å°ºå¯¸èŒƒå›´: w=[{all_wh[:, 0].min():.3f}, {all_wh[:, 0].max():.3f}], h=[{all_wh[:, 1].min():.3f}, {all_wh[:, 1].max():.3f}]")
    
    return all_wh

def comprehensive_training_analysis(model_path, img_path, data_dir, device='cpu'):
    """ç»¼åˆè®­ç»ƒåˆ†æ"""
    print("=" * 60)
    print("å¼€å§‹comprehensiveè®­ç»ƒè¯Šæ–­åˆ†æ...")
    print("=" * 60)
    
    # 1. åŠ è½½æ¨¡å‹å’Œå›¾ç‰‡
    model = load_model(model_path, device)
    img_tensor, img_bgr, ratio, pad = preprocess_image(img_path)
    img_tensor = img_tensor.to(device)
    
    # 2. åŠ è½½å¯¹åº”æ ‡ç­¾
    label_path = img_path.replace('images', 'labels').replace('.jpg', '.txt')
    targets = []
    try:
        with open(label_path, 'r') as f:
            for line in f:
                cls, x, y, w, h = map(float, line.strip().split())
                targets.append([0, cls, x, y, w, h])  # batch_idx=0
        targets = torch.tensor(targets, dtype=torch.float32).to(device)
    except Exception as e:
        print(f"âŒ æ ‡ç­¾è¯»å–å¤±è´¥: {e}")
        targets = torch.zeros((0, 6), dtype=torch.float32).to(device)
    
    print(f"ğŸ“ åˆ†æå›¾ç‰‡: {img_path}")
    print(f"ğŸ“‹ æ ‡ç­¾æ•°é‡: {len(targets)}")
    
    # 3. æ¨¡å‹æ¨ç†
    model.train()
    with torch.no_grad():
        pred = model(img_tensor)
    
    # 4. æŸå¤±åˆ†æ
    if isinstance(pred, list) and len(pred) >= 3 and isinstance(pred[2], list):
        pred_for_loss = pred[2]
    else:
        print("âš ï¸ æ¨¡å‹è¾“å‡ºæ ¼å¼å¼‚å¸¸ï¼Œä½¿ç”¨åŸå§‹è¾“å‡º")
        pred_for_loss = pred
    
    # æ„å»ºæŸå¤±å‡½æ•°
    hyp = {
        'box': 0.05, 'obj': 1.0, 'cls': 0.5,
        'cls_pw': 1.0, 'obj_pw': 1.0,
        'anchor_t': 4.0, 'fl_gamma': 0.0,
        'label_smoothing': 0.0
    }
    compute_loss = ComputeLoss(model, hyp)
    
    try:
        loss_result = compute_loss(pred_for_loss, targets)
        if isinstance(loss_result, tuple) and len(loss_result) == 2:
            total_loss, loss_items = loss_result
            lbox, lobj, lcls = loss_items
            print(f"ğŸ” æŸå¤±åˆ†æ: total={total_loss.item():.4f}, lbox={lbox.item():.4f}, lobj={lobj.item():.4f}, lcls={lcls.item():.4f}")
            print(f"ğŸ“Š æŸå¤±æƒé‡: box={hyp['box']}, obj={hyp['obj']}, cls={hyp['cls']}")
            print(f"âš–ï¸ åŠ æƒæŸå¤±: lbox_weighted={lbox.item()*hyp['box']:.4f}, lobj_weighted={lobj.item()*hyp['obj']:.4f}, lcls_weighted={lcls.item()*hyp['cls']:.4f}")
        else:
            print(f"âŒ æŸå¤±è®¡ç®—æ ¼å¼å¼‚å¸¸: {type(loss_result)}")
    except Exception as e:
        print(f"âŒ æŸå¤±è®¡ç®—å¤±è´¥: {e}")
    
    # 5. ç½®ä¿¡åº¦åˆ†å¸ƒåˆ†æ
    print("\nğŸ” åˆ†æç½®ä¿¡åº¦åˆ†å¸ƒ...")
    conf_stats = analyze_confidence_distribution(pred_for_loss)
    
    # 6. é¢„æµ‹æ¡†åæ ‡åˆ†å¸ƒåˆ†æ
    print("\nğŸ” åˆ†æé¢„æµ‹æ¡†åæ ‡åˆ†å¸ƒ...")
    analyze_box_coordinates(pred_for_loss)
    
    # 7. çœŸå®æ ‡ç­¾åˆ†å¸ƒåˆ†æ
    print("\nğŸ” åˆ†æçœŸå®æ ‡ç­¾åˆ†å¸ƒ...")
    gt_wh = analyze_ground_truth_distribution(data_dir)
    
    # 8. æ·±åº¦é—®é¢˜è¯Šæ–­
    print("\n" + "=" * 60)
    print("ğŸ”¬ æ·±åº¦é—®é¢˜è¯Šæ–­æŠ¥å‘Š:")
    print("=" * 60)
    
    # è¯Šæ–­1: ç½®ä¿¡åº¦å¡Œé™·
    if conf_stats['Mean'] < 0.01:
        print("âŒ é—®é¢˜1: ç½®ä¿¡åº¦ä¸¥é‡å¡Œé™·ï¼")
        print(f"   - å¹³å‡ç½®ä¿¡åº¦ä»… {conf_stats['Mean']:.6f}ï¼Œè¿œä½äºæ­£å¸¸èŒƒå›´(0.1-0.5)")
        print(f"   - {conf_stats['>0.01']:.2%} çš„é¢„æµ‹æ¡†ç½®ä¿¡åº¦ > 0.01")
        print("   ğŸ”§ å»ºè®®: é™ä½objæŸå¤±æƒé‡ï¼Œä»1.0è°ƒæ•´åˆ°0.3-0.5")
    elif conf_stats['Mean'] < 0.05:
        print("âš ï¸ é—®é¢˜1: ç½®ä¿¡åº¦åä½")
        print(f"   - å¹³å‡ç½®ä¿¡åº¦ {conf_stats['Mean']:.4f}ï¼Œå»ºè®®æå‡åˆ°0.1ä»¥ä¸Š")
        print("   ğŸ”§ å»ºè®®: é€‚å½“é™ä½objæŸå¤±æƒé‡")
    else:
        print("âœ… ç½®ä¿¡åº¦åˆ†å¸ƒæ­£å¸¸")
    
    # è¯Šæ–­2: æŸå¤±æƒé‡ä¸å¹³è¡¡
    if hyp['obj'] / hyp['box'] > 10:
        print("âŒ é—®é¢˜2: æŸå¤±æƒé‡ä¸¥é‡ä¸å¹³è¡¡ï¼")
        print(f"   - objæƒé‡({hyp['obj']})æ˜¯boxæƒé‡({hyp['box']})çš„{hyp['obj']/hyp['box']:.1f}å€")
        print("   - æ¨¡å‹è¿‡åº¦å…³æ³¨ç½®ä¿¡åº¦ï¼Œå¿½ç•¥å®šä½ç²¾åº¦")
        print("   ğŸ”§ å»ºè®®: è°ƒæ•´ä¸º box=0.1, obj=0.5, cls=0.5")
    
    # è¯Šæ–­3: é¢„æµ‹æ¡†åæ ‡å¼‚å¸¸
    if len(targets) > 0:
        # è®¡ç®—çœŸå®æ¡†çš„ç»Ÿè®¡ä¿¡æ¯
        gt_boxes = targets[:, 2:6]  # x, y, w, h
        gt_wh_mean = gt_boxes[:, 2:4].mean(dim=0)
        print(f"ğŸ“ çœŸå®æ¡†å¹³å‡å°ºå¯¸: w={gt_wh_mean[0]:.3f}, h={gt_wh_mean[1]:.3f}")
        
        if gt_wh_mean[0] < 0.1 or gt_wh_mean[1] < 0.1:
            print("âš ï¸ é—®é¢˜3: ç›®æ ‡å°ºå¯¸å¾ˆå°ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´anchor")
        elif gt_wh_mean[0] > 0.8 or gt_wh_mean[1] > 0.8:
            print("âš ï¸ é—®é¢˜3: ç›®æ ‡å°ºå¯¸å¾ˆå¤§ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´anchor")
    
    print("\nğŸ¯ æ ¸å¿ƒé—®é¢˜æ€»ç»“:")
    print("1. å¦‚æœlossä¸‹é™ä½†IoUä¸å‡ï¼Œæœ€å¯èƒ½çš„åŸå› æ˜¯ç½®ä¿¡åº¦å¡Œé™·")
    print("2. objæŸå¤±æƒé‡è¿‡é«˜ä¼šå¯¼è‡´æ¨¡å‹'ä¸æ•¢'é¢„æµ‹é«˜ç½®ä¿¡åº¦")
    print("3. å»ºè®®ä¼˜å…ˆè°ƒæ•´æŸå¤±æƒé‡: objä»1.0é™åˆ°0.3-0.5")
    print("4. ç„¶åæ£€æŸ¥anchoræ˜¯å¦ä¸ç›®æ ‡å°ºå¯¸åŒ¹é…")
    
    return conf_stats, gt_wh

def visualize_predictions_vs_gt(model_path, img_path, device='cpu', conf_thresh=0.01):
    """å¯è§†åŒ–é¢„æµ‹æ¡†vsçœŸå®æ¡†å¯¹æ¯”"""
    model = load_model(model_path, device)
    img_tensor, img_bgr, ratio, pad = preprocess_image(img_path)
    img_tensor = img_tensor.to(device)
    
    # åŠ è½½æ ‡ç­¾
    label_path = img_path.replace('images', 'labels').replace('.jpg', '.txt')
    gt_boxes = []
    try:
        with open(label_path, 'r') as f:
            for line in f:
                cls, x, y, w, h = map(float, line.strip().split())
                gt_boxes.append([x, y, w, h])
    except:
        gt_boxes = []
    
    # æ¨ç†
    model.train()
    with torch.no_grad():
        pred = model(img_tensor)
    
    # æå–é¢„æµ‹ç»“æœ
    if isinstance(pred, list) and len(pred) >= 3 and isinstance(pred[2], list):
        pred_for_vis = pred[2]
        # æ‹¼æ¥å¤šä¸ªæ£€æµ‹å¤´
        batch_size = pred_for_vis[0].shape[0]
        all_preds = []
        for p in pred_for_vis:
            p_reshaped = p.view(batch_size, -1, p.shape[-1])
            all_preds.append(p_reshaped)
        pred_cat = torch.cat(all_preds, 1)[0]  # [num_anchors, 6]
    else:
        pred_cat = pred[0]
    
    # åº”ç”¨sigmoidåˆ°ç½®ä¿¡åº¦
    pred_cat[:, 4] = torch.sigmoid(pred_cat[:, 4])
    
    # è¿‡æ»¤é¢„æµ‹æ¡†
    conf_mask = pred_cat[:, 4] > conf_thresh
    valid_preds = pred_cat[conf_mask]
    
    # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
    img_vis = img_bgr.copy()
    h, w = img_vis.shape[:2]
    
    # ç”»çœŸå®æ¡† (ç»¿è‰²)
    for gt_box in gt_boxes:
        x, y, w_gt, h_gt = gt_box
        x1 = int((x - w_gt/2) * w)
        y1 = int((y - h_gt/2) * h)
        x2 = int((x + w_gt/2) * w)
        y2 = int((y + h_gt/2) * h)
        cv2.rectangle(img_vis, (x1, y1), (x2, y2), (0, 255, 0), 3)
        cv2.putText(img_vis, 'GT', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    # ç”»é¢„æµ‹æ¡† (çº¢è‰²)
    pred_count = 0
    for pred_box in valid_preds:
        x, y, w_pred, h_pred, conf, cls = pred_box
        # è¿™é‡Œåæ ‡å¯èƒ½éœ€è¦å½’ä¸€åŒ–å¤„ç†ï¼Œå–å†³äºæ¨¡å‹è¾“å‡ºæ ¼å¼
        x1 = int(max(0, min((x - w_pred/2) * w, w)))
        y1 = int(max(0, min((y - h_pred/2) * h, h)))
        x2 = int(max(0, min((x + w_pred/2) * w, w)))
        y2 = int(max(0, min((y + h_pred/2) * h, h)))
        
        cv2.rectangle(img_vis, (x1, y1), (x2, y2), (0, 0, 255), 2)
        cv2.putText(img_vis, f'{conf:.3f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        pred_count += 1
        
        if pred_count >= 20:  # é™åˆ¶æ˜¾ç¤ºæ¡†æ•°ï¼Œé¿å…å¤ªä¹±
            break
    
    # ä¿å­˜ç»“æœ
    output_path = "debug_output/predictions_vs_gt.jpg"
    os.makedirs("debug_output", exist_ok=True)
    cv2.imwrite(output_path, img_vis)
    
    print(f"é¢„æµ‹æ¡† vs çœŸå®æ¡†å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {output_path}")
    print(f"çœŸå®æ¡†æ•°é‡: {len(gt_boxes)}, æœ‰æ•ˆé¢„æµ‹æ¡†æ•°é‡: {len(valid_preds)}")

if __name__ == "__main__":
    # é…ç½®
    model_path = "model/best_model.pt"
    img_path = "data/images/20250714103802_00000.jpg"
    data_dir = "data"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒè¯Šæ–­åˆ†æ...")
    
    # æ‰§è¡Œç»¼åˆåˆ†æ
    comprehensive_training_analysis(model_path, img_path, data_dir, device)
    
    # æ‰§è¡Œå¯è§†åŒ–å¯¹æ¯”
    print("\nğŸ–¼ï¸ ç”Ÿæˆé¢„æµ‹æ¡†vsçœŸå®æ¡†å¯¹æ¯”å›¾...")
    visualize_predictions_vs_gt(model_path, img_path, device, conf_thresh=0.01)
    
    print("\nâœ… åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹debug_outputç›®å½•ä¸‹çš„åˆ†æç»“æœå›¾ç‰‡ã€‚")
